{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import dask.bag as db\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=db.read_text(\"arxiv-metadata-oai-snapshot.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\"id\":\"0704.0001\",\"submitter\":\"Pavel Nadolsky\",\"authors\":\"C. Bal\\\\\\\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\"title\":\"Calculation of prompt diphoton production cross sections at Tevatron and\\\\n  LHC energies\",\"comments\":\"37 pages, 15 figures; published version\",\"journal-ref\":\"Phys.Rev.D76:013009,2007\",\"doi\":\"10.1103/PhysRevD.76.013009\",\"report-no\":\"ANL-HEP-PR-07-12\",\"categories\":\"hep-ph\",\"license\":null,\"abstract\":\"  A fully differential calculation in perturbative quantum chromodynamics is\\\\npresented for the production of massive photon pairs at hadron colliders. All\\\\nnext-to-leading order perturbative contributions from quark-antiquark,\\\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\\\nall-orders resummation of initial-state gluon radiation valid at\\\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\\\nspecified in which the calculation is most reliable. Good agreement is\\\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\\\nmore detailed tests with CDF and DO data. Predictions are shown for\\\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\\\nthat enhanced sensitivity to the signal can be obtained with judicious\\\\nselection of events.\\\\n\",\"versions\":[{\"version\":\"v1\",\"created\":\"Mon, 2 Apr 2007 19:18:42 GMT\"},{\"version\":\"v2\",\"created\":\"Tue, 24 Jul 2007 20:10:27 GMT\"}],\"update_date\":\"2008-11-26\",\"authors_parsed\":[[\"Bal\\\\u00e1zs\",\"C.\",\"\"],[\"Berger\",\"E. L.\",\"\"],[\"Nadolsky\",\"P. M.\",\"\"],[\"Yuan\",\"C. -P.\",\"\"]]}\\n',\n",
       " '{\"id\":\"0704.0002\",\"submitter\":\"Louis Theran\",\"authors\":\"Ileana Streinu and Louis Theran\",\"title\":\"Sparsity-certifying Graph Decompositions\",\"comments\":\"To appear in Graphs and Combinatorics\",\"journal-ref\":null,\"doi\":null,\"report-no\":null,\"categories\":\"math.CO cs.CG\",\"license\":\"http://arxiv.org/licenses/nonexclusive-distrib/1.0/\",\"abstract\":\"  We describe a new algorithm, the $(k,\\\\\\\\ell)$-pebble game with colors, and use\\\\nit obtain a characterization of the family of $(k,\\\\\\\\ell)$-sparse graphs and\\\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\\\nreceived increased attention in recent years. In particular, our colored\\\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\\\nalso present a new decomposition that certifies sparsity based on the\\\\n$(k,\\\\\\\\ell)$-pebble game with colors. Our work also exposes connections between\\\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\\\nWestermann and Hendrickson.\\\\n\",\"versions\":[{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 02:26:18 GMT\"},{\"version\":\"v2\",\"created\":\"Sat, 13 Dec 2008 17:26:00 GMT\"}],\"update_date\":\"2008-12-13\",\"authors_parsed\":[[\"Streinu\",\"Ileana\",\"\"],[\"Theran\",\"Louis\",\"\"]]}\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': '0704.0001',\n",
       "  'submitter': 'Pavel Nadolsky',\n",
       "  'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
       "  'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies',\n",
       "  'comments': '37 pages, 15 figures; published version',\n",
       "  'journal-ref': 'Phys.Rev.D76:013009,2007',\n",
       "  'doi': '10.1103/PhysRevD.76.013009',\n",
       "  'report-no': 'ANL-HEP-PR-07-12',\n",
       "  'categories': 'hep-ph',\n",
       "  'license': None,\n",
       "  'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n',\n",
       "  'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'},\n",
       "   {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}],\n",
       "  'update_date': '2008-11-26',\n",
       "  'authors_parsed': [['Bal√°zs', 'C.', ''],\n",
       "   ['Berger', 'E. L.', ''],\n",
       "   ['Nadolsky', 'P. M.', ''],\n",
       "   ['Yuan', 'C. -P.', '']]},\n",
       " {'id': '0704.0002',\n",
       "  'submitter': 'Louis Theran',\n",
       "  'authors': 'Ileana Streinu and Louis Theran',\n",
       "  'title': 'Sparsity-certifying Graph Decompositions',\n",
       "  'comments': 'To appear in Graphs and Combinatorics',\n",
       "  'journal-ref': None,\n",
       "  'doi': None,\n",
       "  'report-no': None,\n",
       "  'categories': 'math.CO cs.CG',\n",
       "  'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/',\n",
       "  'abstract': '  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n',\n",
       "  'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 02:26:18 GMT'},\n",
       "   {'version': 'v2', 'created': 'Sat, 13 Dec 2008 17:26:00 GMT'}],\n",
       "  'update_date': '2008-12-13',\n",
       "  'authors_parsed': [['Streinu', 'Ileana', ''], ['Theran', 'Louis', '']]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "records=lines.map(lambda x:json.loads(x))\n",
    "\n",
    "records.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of First Record After JSON LOADS  <class 'str'>\n",
      "Type of First Record After JSON LOADS  <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of First Record After JSON LOADS \",type(lines.take(1)[0]))\n",
    "print(\"Type of First Record After JSON LOADS \",type(records.take(1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.bag.core.Item at 0x152192c5c70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_count=records.count()\n",
    "records_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-14b32562b57d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Records in ArXiv Data is \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecords_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mdask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\multiprocessing.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;31m# Run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         result = get_async(\n\u001b[0m\u001b[0;32m    209\u001b[0m             \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mget_async\u001b[1;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[1;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"waiting\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ready\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"running\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m                 \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Number of Records in ArXiv Data is \",records_count.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_category_list=['stat.ML','cs.LG','cs.AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_docs = (records.filter(lambda x:any(ele in x['categories'] for ele in ai_category_list)==True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Papers published in AI&ML  91496\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Papers published in AI&ML \",ai_docs.count().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_latest_version=lambda x:x['versions'][-1][\"created\"] ## Here -1 indicates the last element in the versions. \n",
    "extract_latest_version_year=lambda x:x['versions'][-1][\"created\"].split(\" \")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_docs_by_year=ai_docs.map(extract_latest_version_year).frequencies().to_dataframe(columns=['submission_year','num_submissions']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metadata = lambda x: {'id': x['id'],\n",
    "                  'title': x['title'],\n",
    "                  'category':x['categories'],\n",
    "                  'abstract':x['abstract'],\n",
    "                 'version':x['versions'][-1]['created']}\n",
    "\n",
    "ai_papers=ai_docs.map(get_metadata).to_dataframe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_papers.to_json(\"ai_papers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_json(\"ai_papers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>abstract</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0047</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>The intelligent acoustic emission locator is...</td>\n",
       "      <td>Sun, 1 Apr 2007 13:06:50 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0050</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>Part I describes an intelligent acoustic emi...</td>\n",
       "      <td>Sun, 1 Apr 2007 18:53:13 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0304</td>\n",
       "      <td>The World as Evolving Information</td>\n",
       "      <td>cs.IT cs.AI math.IT q-bio.PE</td>\n",
       "      <td>This paper discusses the benefits of describ...</td>\n",
       "      <td>Wed, 13 Oct 2010 19:49:16 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0671</td>\n",
       "      <td>Learning from compressed observations</td>\n",
       "      <td>cs.IT cs.LG math.IT</td>\n",
       "      <td>The problem of statistical learning is to co...</td>\n",
       "      <td>Thu, 5 Apr 2007 02:57:15 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0954</td>\n",
       "      <td>Sensor Networks with Random Links: Topology De...</td>\n",
       "      <td>cs.IT cs.LG math.IT</td>\n",
       "      <td>In a sensor network, in practice, the commun...</td>\n",
       "      <td>Fri, 6 Apr 2007 21:58:52 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0  0704.0047  Intelligent location of simultaneously active ...   \n",
       "1  0704.0050  Intelligent location of simultaneously active ...   \n",
       "2  0704.0304                  The World as Evolving Information   \n",
       "3  0704.0671              Learning from compressed observations   \n",
       "4  0704.0954  Sensor Networks with Random Links: Topology De...   \n",
       "\n",
       "                       category  \\\n",
       "0                   cs.NE cs.AI   \n",
       "1                   cs.NE cs.AI   \n",
       "2  cs.IT cs.AI math.IT q-bio.PE   \n",
       "3           cs.IT cs.LG math.IT   \n",
       "4           cs.IT cs.LG math.IT   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    The intelligent acoustic emission locator is...   \n",
       "1    Part I describes an intelligent acoustic emi...   \n",
       "2    This paper discusses the benefits of describ...   \n",
       "3    The problem of statistical learning is to co...   \n",
       "4    In a sensor network, in practice, the commun...   \n",
       "\n",
       "                         version  \n",
       "0   Sun, 1 Apr 2007 13:06:50 GMT  \n",
       "1   Sun, 1 Apr 2007 18:53:13 GMT  \n",
       "2  Wed, 13 Oct 2010 19:49:16 GMT  \n",
       "3   Thu, 5 Apr 2007 02:57:15 GMT  \n",
       "4   Fri, 6 Apr 2007 21:58:52 GMT  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate records which contain different flags\n",
    "metadata = metadata.drop(columns = 'category').groupby(by = ['id', 'title', 'abstract'],as_index = False).max()\n",
    "# remove abstracts from withdrawn records\n",
    "metadata = metadata[metadata['abstract'].str.contains('paper has been withdrawn') == False]\n",
    "# lower abstract and remove numbers, punctuation, and special characters\n",
    "#metadata['abstract'] = [a.strip() for a in metadata['abstract']]\n",
    "metadata['abstract'] = [a.lower().strip() for a in metadata['abstract']]\n",
    "metadata['abstract'] = metadata['abstract'].str.replace('\\n', ' ', regex = False).str.replace(r'\\s\\s+', ' ', regex = True)\n",
    "metadata['abstract'] = metadata['abstract'].str.replace('([.,!?()])', r' \\1 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        the intelligent acoustic emission locator is d...\n",
       "1        part i describes an intelligent acoustic emiss...\n",
       "2        this paper discusses the benefits of describin...\n",
       "3        the problem of statistical learning is to cons...\n",
       "4        in a sensor network ,  in practice ,  the comm...\n",
       "                               ...                        \n",
       "91491    we outline the rationale and preliminary resul...\n",
       "91492    in this article we give several new results on...\n",
       "91493    in quantum physics ,  a measurement is represe...\n",
       "91494    probability-like parameters appearing in some ...\n",
       "91495    graphical models of probabilistic dependencies...\n",
       "Name: abstract, Length: 91484, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPROCESSING FUNCTIONS ###\n",
    "# lemmatizing function\n",
    "def lemmatize_text(text_string, lemmatizer):\n",
    "    word_list = nltk.word_tokenize(text_string)\n",
    "    # Lemmatize list of words and join\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_output\n",
    "### PREPROCESSING FOR EMBEDDING AND SKLEARN VECTORIZERS ###\n",
    "metadata['abstract_no_punct'] = metadata['abstract'].str.replace('-', '', regex = False).str.replace(r'\\n', ' ', regex = False).str.replace(r'[^a-z ]+', ' ', regex = True).str.replace(r'\\s\\s+', ' ', regex = True)\n",
    "# lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "metadata['abstract_lemmatized'] = [lemmatize_text(ab, lemmatizer) for ab in metadata['abstract']]\n",
    "# generate formatted stop words + single letters and spelled numbers (expand as necesary)\n",
    "stopwords_nltk = set([re.sub( r'[^a-z ]+', '',s) for s in stopwords.words('english')] + list(string.ascii_lowercase) + ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'])\n",
    "# exclude stopwords\n",
    "metadata['abstract_lemmatized_no_stopwords'] = metadata['abstract_lemmatized'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords_nltk]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sandu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>version</th>\n",
       "      <th>abstract_no_punct</th>\n",
       "      <th>abstract_lemmatized</th>\n",
       "      <th>abstract_lemmatized_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0047</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>the intelligent acoustic emission locator is d...</td>\n",
       "      <td>Sun, 1 Apr 2007 13:06:50 GMT</td>\n",
       "      <td>the intelligent acoustic emission locator is d...</td>\n",
       "      <td>the intelligent acoustic emission locator is d...</td>\n",
       "      <td>intelligent acoustic emission locator describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0050</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>part i describes an intelligent acoustic emiss...</td>\n",
       "      <td>Sun, 1 Apr 2007 18:53:13 GMT</td>\n",
       "      <td>part i describes an intelligent acoustic emiss...</td>\n",
       "      <td>part i describes an intelligent acoustic emiss...</td>\n",
       "      <td>part describes intelligent acoustic emission l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0304</td>\n",
       "      <td>The World as Evolving Information</td>\n",
       "      <td>this paper discusses the benefits of describin...</td>\n",
       "      <td>Wed, 13 Oct 2010 19:49:16 GMT</td>\n",
       "      <td>this paper discusses the benefits of describin...</td>\n",
       "      <td>this paper discus the benefit of describing th...</td>\n",
       "      <td>paper discus benefit describing world informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0671</td>\n",
       "      <td>Learning from compressed observations</td>\n",
       "      <td>the problem of statistical learning is to cons...</td>\n",
       "      <td>Thu, 5 Apr 2007 02:57:15 GMT</td>\n",
       "      <td>the problem of statistical learning is to cons...</td>\n",
       "      <td>the problem of statistical learning is to cons...</td>\n",
       "      <td>problem statistical learning construct predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0954</td>\n",
       "      <td>Sensor Networks with Random Links: Topology De...</td>\n",
       "      <td>in a sensor network ,  in practice ,  the comm...</td>\n",
       "      <td>Fri, 6 Apr 2007 21:58:52 GMT</td>\n",
       "      <td>in a sensor network in practice the communicat...</td>\n",
       "      <td>in a sensor network , in practice , the commun...</td>\n",
       "      <td>sensor network , practice , communication amon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0  0704.0047  Intelligent location of simultaneously active ...   \n",
       "1  0704.0050  Intelligent location of simultaneously active ...   \n",
       "2  0704.0304                  The World as Evolving Information   \n",
       "3  0704.0671              Learning from compressed observations   \n",
       "4  0704.0954  Sensor Networks with Random Links: Topology De...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  the intelligent acoustic emission locator is d...   \n",
       "1  part i describes an intelligent acoustic emiss...   \n",
       "2  this paper discusses the benefits of describin...   \n",
       "3  the problem of statistical learning is to cons...   \n",
       "4  in a sensor network ,  in practice ,  the comm...   \n",
       "\n",
       "                         version  \\\n",
       "0   Sun, 1 Apr 2007 13:06:50 GMT   \n",
       "1   Sun, 1 Apr 2007 18:53:13 GMT   \n",
       "2  Wed, 13 Oct 2010 19:49:16 GMT   \n",
       "3   Thu, 5 Apr 2007 02:57:15 GMT   \n",
       "4   Fri, 6 Apr 2007 21:58:52 GMT   \n",
       "\n",
       "                                   abstract_no_punct  \\\n",
       "0  the intelligent acoustic emission locator is d...   \n",
       "1  part i describes an intelligent acoustic emiss...   \n",
       "2  this paper discusses the benefits of describin...   \n",
       "3  the problem of statistical learning is to cons...   \n",
       "4  in a sensor network in practice the communicat...   \n",
       "\n",
       "                                 abstract_lemmatized  \\\n",
       "0  the intelligent acoustic emission locator is d...   \n",
       "1  part i describes an intelligent acoustic emiss...   \n",
       "2  this paper discus the benefit of describing th...   \n",
       "3  the problem of statistical learning is to cons...   \n",
       "4  in a sensor network , in practice , the commun...   \n",
       "\n",
       "                    abstract_lemmatized_no_stopwords  \n",
       "0  intelligent acoustic emission locator describe...  \n",
       "1  part describes intelligent acoustic emission l...  \n",
       "2  paper discus benefit describing world informat...  \n",
       "3  problem statistical learning construct predict...  \n",
       "4  sensor network , practice , communication amon...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(metadata['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = metadata['abstract_lemmatized_no_stopwords'].tolist()\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "keywords = [word_tokenize(keyword.lower()) for keyword in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_commas(doc):\n",
    "    no_commas = [t for t in doc if t!=',']\n",
    "    return(no_commas)\n",
    "\n",
    "keywords = [no_commas(kw) for kw in keywords]\n",
    "processed_keywords = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intelligent',\n",
       " 'acoustic',\n",
       " 'emission',\n",
       " 'locator',\n",
       " 'described',\n",
       " 'part',\n",
       " 'part',\n",
       " 'ii',\n",
       " 'discus',\n",
       " 'blind',\n",
       " 'source',\n",
       " 'separation',\n",
       " 'time',\n",
       " 'delay',\n",
       " 'estimation',\n",
       " 'location',\n",
       " 'simultaneously',\n",
       " 'active',\n",
       " 'continuous',\n",
       " 'acoustic',\n",
       " 'emission',\n",
       " 'source',\n",
       " '.',\n",
       " 'location',\n",
       " 'acoustic',\n",
       " 'emission',\n",
       " 'complicated',\n",
       " 'aircraft',\n",
       " 'frame',\n",
       " 'structure',\n",
       " 'difficult',\n",
       " 'problem',\n",
       " 'non-destructive',\n",
       " 'testing',\n",
       " '.',\n",
       " 'article',\n",
       " 'describes',\n",
       " 'intelligent',\n",
       " 'acoustic',\n",
       " 'emission',\n",
       " 'source',\n",
       " 'locator',\n",
       " '.',\n",
       " 'intelligent',\n",
       " 'locator',\n",
       " 'comprises',\n",
       " 'sensor',\n",
       " 'antenna',\n",
       " 'general',\n",
       " 'regression',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'solves',\n",
       " 'location',\n",
       " 'problem',\n",
       " 'based',\n",
       " 'learning',\n",
       " 'example',\n",
       " '.',\n",
       " 'locator',\n",
       " 'performance',\n",
       " 'wa',\n",
       " 'tested',\n",
       " 'different',\n",
       " 'test',\n",
       " 'specimen',\n",
       " '.',\n",
       " 'test',\n",
       " 'shown',\n",
       " 'accuracy',\n",
       " 'location',\n",
       " 'depends',\n",
       " 'sound',\n",
       " 'velocity',\n",
       " 'attenuation',\n",
       " 'specimen',\n",
       " 'dimension',\n",
       " 'tested',\n",
       " 'area',\n",
       " 'property',\n",
       " 'stored',\n",
       " 'data',\n",
       " '.',\n",
       " 'location',\n",
       " 'accuracy',\n",
       " 'achieved',\n",
       " 'intelligent',\n",
       " 'locator',\n",
       " 'comparable',\n",
       " 'obtained',\n",
       " 'conventional',\n",
       " 'triangulation',\n",
       " 'method',\n",
       " 'applicability',\n",
       " 'intelligent',\n",
       " 'locator',\n",
       " 'general',\n",
       " 'since',\n",
       " 'analysis',\n",
       " 'sonic',\n",
       " 'ray',\n",
       " 'path',\n",
       " 'avoided',\n",
       " '.',\n",
       " 'promising',\n",
       " 'method',\n",
       " 'non-destructive',\n",
       " 'testing',\n",
       " 'aircraft',\n",
       " 'frame',\n",
       " 'structure',\n",
       " 'acoustic',\n",
       " 'emission',\n",
       " 'method',\n",
       " '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_keywords[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
