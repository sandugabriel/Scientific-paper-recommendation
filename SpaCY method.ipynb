{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop_words_ = set(stopwords.words('english'))\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "def black_txt(token):\n",
    "    return  token not in stop_words_ and token not in list(string.punctuation)  and len(token)>2   \n",
    "\n",
    "def clean_txt(text):\n",
    "    clean_text = []\n",
    "    clean_text2 = []\n",
    "    text = re.sub(\"'\", \"\",text)\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text) \n",
    "    text = text.replace(\"nbsp\", \"\")\n",
    "    clean_text = [ wn.lemmatize(word, pos=\"v\") for word in word_tokenize(text.lower()) if black_txt(word)]\n",
    "    clean_text2 = [word for word in clean_text if black_txt(word)]\n",
    "    return \" \".join(clean_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('ai_papers.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the dataset\n",
    "df['abstract'] = df['abstract'].apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>abstract</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0047</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>intelligent acoustic emission locator describe...</td>\n",
       "      <td>Sun, 1 Apr 2007 13:06:50 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0050</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>part describe intelligent acoustic emission lo...</td>\n",
       "      <td>Sun, 1 Apr 2007 18:53:13 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0304</td>\n",
       "      <td>The World as Evolving Information</td>\n",
       "      <td>cs.IT cs.AI math.IT q-bio.PE</td>\n",
       "      <td>paper discuss benefit describe world informati...</td>\n",
       "      <td>Wed, 13 Oct 2010 19:49:16 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0671</td>\n",
       "      <td>Learning from compressed observations</td>\n",
       "      <td>cs.IT cs.LG math.IT</td>\n",
       "      <td>problem statistical learn construct predictor ...</td>\n",
       "      <td>Thu, 5 Apr 2007 02:57:15 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0954</td>\n",
       "      <td>Sensor Networks with Random Links: Topology De...</td>\n",
       "      <td>cs.IT cs.LG math.IT</td>\n",
       "      <td>sensor network practice communication among se...</td>\n",
       "      <td>Fri, 6 Apr 2007 21:58:52 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0  0704.0047  Intelligent location of simultaneously active ...   \n",
       "1  0704.0050  Intelligent location of simultaneously active ...   \n",
       "2  0704.0304                  The World as Evolving Information   \n",
       "3  0704.0671              Learning from compressed observations   \n",
       "4  0704.0954  Sensor Networks with Random Links: Topology De...   \n",
       "\n",
       "                       category  \\\n",
       "0                   cs.NE cs.AI   \n",
       "1                   cs.NE cs.AI   \n",
       "2  cs.IT cs.AI math.IT q-bio.PE   \n",
       "3           cs.IT cs.LG math.IT   \n",
       "4           cs.IT cs.LG math.IT   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  intelligent acoustic emission locator describe...   \n",
       "1  part describe intelligent acoustic emission lo...   \n",
       "2  paper discuss benefit describe world informati...   \n",
       "3  problem statistical learn construct predictor ...   \n",
       "4  sensor network practice communication among se...   \n",
       "\n",
       "                         version  \n",
       "0   Sun, 1 Apr 2007 13:06:50 GMT  \n",
       "1   Sun, 1 Apr 2007 18:53:13 GMT  \n",
       "2  Wed, 13 Oct 2010 19:49:16 GMT  \n",
       "3   Thu, 5 Apr 2007 02:57:15 GMT  \n",
       "4   Fri, 6 Apr 2007 21:58:52 GMT  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the cleaned dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "list_docs = []\n",
    "for i in range(len(df)):\n",
    "    doc = nlp(\"u'\" + df['abstract'][i] + \"'\")\n",
    "    list_docs.append((doc,i))\n",
    "print(len(list_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSimWithSpaCy(nlp, df, user_text, n=6):\n",
    "    # Calculate similarity using spaCy\n",
    "    list_sim =[]\n",
    "    doc1 = nlp(\"u'\" + user_text + \"'\")\n",
    "    for i in df.index:\n",
    "        try:\n",
    "            doc2 = list_docs[i][0]\n",
    "            score = doc1.similarity(doc2)\n",
    "            list_sim.append((doc1, doc2, list_docs[i][1],score))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return  list_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"face recognition deep learning convolutional neural networks\"\n",
    "user_query = clean_txt(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df3 = calculateSimWithSpaCy(nlp, df, user_query, n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recom_spacy = pd.DataFrame(df3).sort_values([3], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recom_spacy.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_spacy = df_recom_spacy[2]\n",
    "list_scores = df_recom_spacy[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(top, df_all, scores):\n",
    "    recommendation = pd.DataFrame(columns = ['Title', 'score'])\n",
    "    count = 0\n",
    "    for i in top:\n",
    "        recommendation.at[count, 'Title'] = df['title'][i]\n",
    "        recommendation.at[count, 'score'] =  scores[count]\n",
    "        count += 1\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendation(index_spacy, df, list_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
